{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iRCfLMmkvLZb"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WxAzWoJEvZHh",
        "outputId": "b4061237-bfb4-45e8-fa9d-002db4eb6c7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[], normalizer=None, pre_tokenizer=Whitespace(), post_processor=None, decoder=None, model=BPE(dropout=None, unk_token=\"[UNK]\", continuing_subword_prefix=None, end_of_word_suffix=None, fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={}, merges=[]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = BpeTrainer(\n",
        "    vocab_size=50000,\n",
        "    special_tokens=[\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        ")"
      ],
      "metadata": {
        "id": "FNbg0DgtvdU-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"cleaned_output.txt\", \"rb\") as f:\n",
        "    data = f.read()"
      ],
      "metadata": {
        "id": "SD2_EUTrvnkF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"cleaned_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(data.decode(\"utf-8\", errors=\"ignore\"))\n",
        "\n",
        "tokenizer.train(files=[\"cleaned_output.txt\"], trainer=trainer)"
      ],
      "metadata": {
        "id": "QfmVIzfJv-Wx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save(\"sanskrit_bpe_tokenizer.json\")\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZMULdBu6vzh5",
        "outputId": "b051d729-eaef-491f-b9e4-7656ba01b0c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"[UNK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":1, \"content\":\"[PAD]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":2, \"content\":\"[CLS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":3, \"content\":\"[SEP]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":4, \"content\":\"[MASK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}], normalizer=None, pre_tokenizer=Whitespace(), post_processor=None, decoder=None, model=BPE(dropout=None, unk_token=\"[UNK]\", continuing_subword_prefix=None, end_of_word_suffix=None, fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={\"[UNK]\":0, \"[PAD]\":1, \"[CLS]\":2, \"[SEP]\":3, \"[MASK]\":4, ...}, merges=[(\"्\", \"य\"), (\"्\", \"र\"), (\"्\", \"त\"), (\"र\", \"्\"), (\"ा\", \"न\"), ...]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "\n",
        "with open(\"cleaned_output.txt\", \"rb\") as f:\n",
        "    raw_data = f.read(10000)\n",
        "    result = chardet.detect(raw_data)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "P7fRxkGcwHKi",
        "outputId": "e2acbc6d-1b17-42ee-e2af-5e7e547ce1fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer.encode(\"अहं संस्कृतं पठामि\")\n",
        "print(encoding.ids)\n",
        "print(encoding.tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lbPqYOe9wn67",
        "outputId": "f602a808-d460-4c55-ecb2-085e43738f98"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1193, 7337, 1355, 18947]\n",
            "['अहं', 'संस्कृतं', 'पठ', 'ामि']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n"
      ],
      "metadata": {
        "id": "wTc7dK5pwqkp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class SanskritEmbeddings(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, max_seq_length=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_embeddings = nn.Embedding(max_seq_length, d_model)\n",
        "        position_ids = torch.arange(max_seq_length).unsqueeze(0)\n",
        "        self.register_buffer('position_ids', position_ids)\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        seq_length = input_ids.size(1)\n",
        "\n",
        "        word_embeds = self.word_embeddings(input_ids)\n",
        "\n",
        "        position_ids = self.position_ids[:, :seq_length]\n",
        "        pos_embeds = self.position_embeddings(position_ids)\n",
        "        embeddings = word_embeds + pos_embeds\n",
        "\n",
        "        embeddings = self.layer_norm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "7M8bu-RWwwT1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50000\n",
        "d_model = 512\n",
        "max_seq_length = 512"
      ],
      "metadata": {
        "id": "Go4zC4eVxHrt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_layer = SanskritEmbeddings(vocab_size, d_model, max_seq_length)"
      ],
      "metadata": {
        "id": "XpPNuiLZxM51"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jt0hySh1xN2p",
        "outputId": "2ab5d2c5-69a3-46c6-e130-e37f5c58135f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SanskritEmbeddings(\n",
            "  (word_embeddings): Embedding(50000, 512)\n",
            "  (position_embeddings): Embedding(512, 512)\n",
            "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE\n",
        "input_ids = torch.tensor([[1, 45, 23, 78, 123, 456, 789, 234, 567, 890],\n",
        "                         [2, 46, 24, 79, 124, 457, 790, 235, 568, 891]])"
      ],
      "metadata": {
        "id": "Tdd49E9bxRJU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_embeddings = embeddings_layer(input_ids)\n",
        "print(f\"Input shape: {input_ids.shape}\")\n",
        "print(f\"Output embeddings shape: {output_embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1mfj50PgxUhd",
        "outputId": "3adbe360-fef9-4fce-984d-aca4aa46ef3a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 10])\n",
            "Output embeddings shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SanskritSinusoidalEmbeddings(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, max_seq_length=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
        "                           (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        seq_length = input_ids.size(1)\n",
        "\n",
        "        word_embeds = self.word_embeddings(input_ids)\n",
        "\n",
        "        embeddings = word_embeds + self.pe[:, :seq_length]\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        return embeddings\n"
      ],
      "metadata": {
        "id": "Ot-IS40_xaMR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50000\n",
        "d_model = 512\n",
        "max_seq_length = 512"
      ],
      "metadata": {
        "id": "Qt7Ys6Hi-PIg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SanskritSinusoidalEmbeddings(vocab_size, d_model, max_seq_length)\n"
      ],
      "metadata": {
        "id": "mu9IVms2-Rww"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sinusoidal Embeddings Model Created:\")\n",
        "print(f\"Vocab size: {vocab_size}\")\n",
        "print(f\"Embedding dim: {d_model}\")\n",
        "print(f\"Max sequence length: {max_seq_length}\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QNT1CfGl-T0C",
        "outputId": "a7fee1eb-72ba-4cfc-e930-25f5d7208512"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sinusoidal Embeddings Model Created:\n",
            "Vocab size: 50000\n",
            "Embedding dim: 512\n",
            "Max sequence length: 512\n",
            "Total parameters: 25,600,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'sanskrit_sinusoidal_embeddings.pt')\n",
        "torch.save(model.state_dict(), 'sanskrit_sinusoidal_state_dict.pt')\n",
        "\n",
        "output_embeddings = sinusoidal_embeddings(input_ids)"
      ],
      "metadata": {
        "id": "SvSSiLbOx4hM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sinusoidal_model():\n",
        "    model = torch.load('sanskrit_sinusoidal_embeddings.pt', weights_only=False)\n",
        "    model.eval()\n",
        "    print(\"Sinusoidal model loaded successfully!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "lSVDuZ5J-qUs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50000\n",
        "d_model = 512\n",
        "max_seq_length = 512\n"
      ],
      "metadata": {
        "id": "ascsEJsD-tO_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = SanskritSinusoidalEmbeddings(vocab_size, d_model, max_seq_length)\n",
        "model.load_state_dict(torch.load('sanskrit_sinusoidal_state_dict.pt'))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CXFNNK8i-wlW",
        "outputId": "7a239fca-556b-4f43-9a9f-1cad89fa4c0f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SanskritSinusoidalEmbeddings(\n",
              "  (word_embeddings): Embedding(50000, 512)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"✓ Sinusoidal model loaded via state_dict!\")\n",
        "loaded_model = load_sinusoidal_model()\n",
        "print(loaded_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9IHsfrz_-zQH",
        "outputId": "372c6120-300c-4de3-ea01-ef0898ea0a04"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Sinusoidal model loaded via state_dict!\n",
            "Sinusoidal model loaded successfully!\n",
            "SanskritSinusoidalEmbeddings(\n",
            "  (word_embeddings): Embedding(50000, 512)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2b4182e4",
        "outputId": "c3087ca1-b218-4542-f318-29a2d6e68793"
      },
      "source": [
        "loaded_model = load_sinusoidal_model()\n",
        "sample_input_ids = torch.tensor([[1, 45, 23, 78, 123, 456, 789, 234, 567, 890],\n",
        "                                 [2, 46, 24, 79, 124, 457, 790, 235, 568, 891]]) # Using the same example input as before\n",
        "\n",
        "output_embeddings = loaded_model(sample_input_ids)\n",
        "print(f\"Input shape: {sample_input_ids.shape}\")\n",
        "print(f\"Output embeddings shape: {output_embeddings.shape}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sinusoidal model loaded successfully!\n",
            "Input shape: torch.Size([2, 10])\n",
            "Output embeddings shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQLIH9ECKoCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9H_3BF3OKoKq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}